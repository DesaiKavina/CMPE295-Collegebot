{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"chatbot_train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"6_1VonLzGbKT","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE39yho1GbKX","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import unicode_literals\n","\n","import torch\n","from torch.jit import script, trace\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import csv\n","import random\n","import re\n","import os\n","import unicodedata\n","import codecs\n","from io import open\n","import itertools\n","import math\n","import pickle\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9O1zlxlGbKZ","colab_type":"code","colab":{}},"source":["# Default word tokens\n","PAD_token = 0  # Used for padding short sentences\n","SOS_token = 1  # Start-of-sentence token\n","EOS_token = 2  # End-of-sentence token\n","\n","class Voc:\n","    def __init__(self, name):\n","        self.name = name\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3  # Count SOS, EOS, PAD\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    # Remove words below a certain count threshold\n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Reinitialize dictionaries\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3 # Count default tokens\n","\n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vqt9_NVJGbKb","colab_type":"code","outputId":"e7cc0691-2d98-419f-b2ab-21f09b23deee","executionInfo":{"status":"ok","timestamp":1588795416829,"user_tz":420,"elapsed":390,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["datafile = os.path.join(\".\",\"some_data.txt\")\n","print(\"Datafile : \", datafile)\n","MAX_LENGTH = 1000  # Maximum sentence length to consider\n","import json\n","with open('contractions.json', 'r') as fp:\n","    good_prefixes = json.load(fp)\n","    good_prefixes = {key.strip().lower():value.strip().lower() for key,value in good_prefixes.items()}\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Datafile :  ./some_data.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7mDH9K2pGbKe","colab_type":"code","outputId":"df6d768b-1d01-42ef-eb8f-bf590f62938c","executionInfo":{"status":"ok","timestamp":1588795417760,"user_tz":420,"elapsed":385,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["# Turn a Unicode string to plain ASCII, thanks to\n","# https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = \" \".join([good_prefixes[each] if each in good_prefixes else each for each in s.split()])\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","#    s = re.sub(r'\\.+', \" \", s)\n","    pattern = re.compile(r\"(.)\\1{3,}\")\n","    s=  pattern.sub(r\"\\1\\1\", s)\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","# Read query/response pairs and return a voc object\n","def readVocs(datafile, corpus_name):\n","    print(\"Reading lines...\")\n","    # Read the file and split into lines\n","    lines = open(datafile, encoding='utf-8').\\\n","        read().strip().split(\"\\n\")\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('*-*')] for l in lines]\n","    voc = Voc(corpus_name)\n","    return voc, pairs\n","\n","# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n","def filterPair(p):\n","    # Input sequences need to preserve the last word for EOS token\n","    if len(p)==2:\n","        return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split('  ')) < MAX_LENGTH\n","\n","# Filter pairs using filterPair condition\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","# Using the functions defined above, return a populated voc object and pairs list\n","def loadPrepareData(corpus_name, datafile, save_dir):\n","    print(\"Start preparing training data ...\")\n","    voc, pairs = readVocs(datafile, corpus_name)\n","    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","    print(\"Counted words:\", voc.num_words)\n","    return voc, pairs\n","\n","\n","# Load/Assemble voc and pairs\n","save_dir = os.path.join(\".\",\"model\", \"save\")\n","corpus_name = 'chatbot'\n","voc, pairs = loadPrepareData(corpus_name, datafile, save_dir)\n","# Print some pairs to validate\n","print(\"\\npairs:\")\n","for pair in pairs[:10]:\n","    print(pair)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Start preparing training data ...\n","Reading lines...\n","Read 150 sentence pairs\n","Trimmed to 150 sentence pairs\n","Counting words...\n","Counted words: 1754\n","\n","pairs:\n","['\"how do i withdraw from ou classes ?', 'see the ou calendar for deadlines . you may withdraw from courses after the refund deadline and receive a “w” grade by securing the approval signature of the instructor and cpge associate dean on a withdrawal petition form . no refund is given . failure to withdraw officially from a course generates a failing grade of “f” or “wu” . \"']\n","['\"what if the course(s) i have selected have been cancelled ?', 'refer to the department for a current listing of available classes . \"']\n","['\"what types of scholarship opportunities are at sjsu ?', 'there are three main sources of scholarships: campus based scholarships - the application period for campus based scholarships is from january through may 1 . the application can be found at scholarships when it is available . department based scholarships - the application for department based scholarships varies from major to major . please check with the major department office for more information . private (outside donor) \"']\n","['\"an outside donor or organization will be sending a scholarship check to sjsu . where should the check be sent, and how soon will the money become available ?', 'all scholarship checks should be mailed to the financial aid and scholarship office, attn: scholarship coordinator, one washington square, san jose, ca 95192-0036 . please make the scholarship check payable to san jose state university . checks should include the student\\'s sjsu id# . if the id# is not available, please include first and last name as well as either the student\\'s date of birth or last four digits of the student\\'s social security number . funds will typically be posted to student\\'s account within 7-10 business days of the check being received . \"']\n","['\"are there other scholarship opportunities besides here at sjsu ?', 'yes ! be sure to check online scholarship search sites such as fastweb and college board . also contact your high school, community center, employer or parent\\'s employer, sorority/fraternity and or religious organization to see what scholarship opportunities they may provide . beware of any scholarship opportunities that require a payment - scholarship funding does not require any repayment . \"']\n","['\"do students have to file a fafsa to apply for scholarships ?', 'while a fafsa is not needed to be considered for scholarships, sjsu recommends that all students file a fafsa to be eligible for as many scholarships as possible . \"']\n","['\"can international students apply for scholarships ?', 'international students can apply for any merit based scholarship at sjsu . be sure to check with outside donors about scholarship policies . \"']\n","['\"can a student receive scholarship payments if enrolled through open university ?', 'no . students cannot receive scholarship payments while in open university . a student must be a matriculated student working towards a degree in order to receive aid . \"']\n","['\"resouces about health insurance', 'http://stage .sjsu .edu/isss/resources/health-insurance/ \"']\n","['\"how do i get or replace a library card ?', 'if you are a new borrower, please fill out the application online at the library or from home . you will then need to come in to king library or any san jose public library branch to pick up your library card in person . please bring a valid, current government-issued photo id such as a california driver’s license or a california id card . to get a replacement library card, bring a valid photo id with proof of current address and speak with a staff member at the circulation desk . in order to borrow items from the sjsu library, you shall need to fill out the request a onesearch account form using your sjpl library card number and pin . you will need an e-mail address, as the the sjsu system requires one . san jose state patrons: if you are an sjsu student, faculty, or staff, your sjsu tower card serves as your library card . to log in to your library account, you will use your sjsu id number and sjsuone password . in order to check out items from the public library, you will need a san jose library account . apply for an sjpl library card here or go to the circulation desk in the king library or at one of the branches . \"']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l0uqlNDqGbKg","colab_type":"code","outputId":"5bd81d42-bfd7-4e85-fa9a-1a570f8e57f9","executionInfo":{"status":"ok","timestamp":1588795419723,"user_tz":420,"elapsed":463,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["MIN_COUNT = 1   # Minimum word count threshold for trimming\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Trim words used under the MIN_COUNT from the voc\n","    voc.trim(MIN_COUNT)\n","    # Filter out pairs with trimmed words\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Check input sentence\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Check output sentence\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Trim voc and pairs\n","pairs = trimRareWords(voc, pairs, MIN_COUNT)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["keep_words 1751 / 1751 = 1.0000\n","Trimmed from 150 pairs to 150, 1.0000 of total\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9equOo5qGbKi","colab_type":"code","colab":{}},"source":["with open(os.path.join(\".\",\"pickles\",\"vocab.file\"), \"wb\") as f:\n","    pickle.dump(voc, f, pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwzIsnw0GbKk","colab_type":"code","outputId":"e45a7273-920b-4a3b-8a67-2cb5fe539b34","executionInfo":{"status":"ok","timestamp":1588795421829,"user_tz":420,"elapsed":432,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["with open(os.path.join(\".\",\"pickles\",\"vocab.file\"), \"rb\") as f:\n","    dump = pickle.load(f)\n","print(dir(dump))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'addSentence', 'addWord', 'index2word', 'name', 'num_words', 'trim', 'trimmed', 'word2count', 'word2index']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"jvIciQRCGbKm","colab_type":"code","outputId":"e035eb10-aefe-479f-e652-71ebfbbaa99f","executionInfo":{"status":"ok","timestamp":1588795422785,"user_tz":420,"elapsed":532,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n","\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.ByteTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len\n","\n","\n","# Example for validation\n","small_batch_size = 5\n","batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n","input_variable, lengths, target_variable, mask, max_target_len = batches\n","\n","print(\"input_variable:\", input_variable)\n","print(\"lengths:\", lengths)\n","print(\"target_variable:\", target_variable)\n","print(\"mask:\", mask)\n","print(\"max_target_len:\", max_target_len)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["input_variable: tensor([[ 496,  654,    3,   54,   54],\n","        [  41,   81,    4,   55,   55],\n","        [ 680,  589,    5,    5,    5],\n","        [ 868,   37,  533,   57,   57],\n","        [  45,  762,  330, 1632, 1632],\n","        [ 295, 1420,  274,  420,  420],\n","        [  12, 1421, 1474,  297,  297],\n","        [1472,   16,   37,   10,   10],\n","        [ 703,  189,  420,    2,    2],\n","        [ 224,  198, 1475,    0,    0],\n","        [ 762,  194,   10,    0,    0],\n","        [  45, 1422,    2,    0,    0],\n","        [  24,   10,    0,    0,    0],\n","        [1651,    2,    0,    0,    0],\n","        [   7,    0,    0,    0,    0],\n","        [1548,    0,    0,    0,    0],\n","        [  16,    0,    0,    0,    0],\n","        [  86,    0,    0,    0,    0],\n","        [   5,    0,    0,    0,    0],\n","        [ 277,    0,    0,    0,    0],\n","        [  45,    0,    0,    0,    0],\n","        [ 727,    0,    0,    0,    0],\n","        [ 420,    0,    0,    0,    0],\n","        [ 703,    0,    0,    0,    0],\n","        [ 267,    0,    0,    0,    0],\n","        [  10,    0,    0,    0,    0],\n","        [   2,    0,    0,    0,    0]])\n","lengths: tensor([27, 14, 12,  9,  9])\n","target_variable: tensor([[ 167,   12,   28,   55,   55],\n","        [  16, 1421, 1476,   17,   17],\n","        [  17,  589,  179,   57,   57],\n","        [  86,  782,   81, 1632, 1632],\n","        [ 277,  194,  468,  179,  179],\n","        [  45,   12,   17,  297,  297],\n","        [ 727,  134,   18,   23,   23],\n","        [ 179,  905,   11,  179,  179],\n","        [ 703,  637,  330, 1549, 1549],\n","        [ 267,   12,  274,  156,  156],\n","        [ 194, 1423,   14,  905,  905],\n","        [  42,  443,  277,  138,  138],\n","        [1652,   45,   16,   59,   59],\n","        [  95, 1109,  568, 1633, 1633],\n","        [ 179,   55,  135,   17,   17],\n","        [1548,   17,  274,   18,   18],\n","        [1549,  629,  173,  277,  277],\n","        [ 156,   12,  143,   25,   25],\n","        [ 279,  461,   12,  297,  297],\n","        [  12,  693, 1440, 1610, 1610],\n","        [1548, 1072, 1441,   28,   28],\n","        [1549,  826,   25, 1634, 1634],\n","        [ 319,   23,  360,   45,   45],\n","        [  40,  905,   32,   12,   12],\n","        [  16,  246, 1442,   74,   74],\n","        [ 282, 1424,  240, 1635, 1635],\n","        [ 703,  179,   51,  349,  349],\n","        [  95,   81, 1091,   14,   14],\n","        [  25,   45, 1443,   12,   12],\n","        [1653,  179,   32, 1548, 1548],\n","        [ 297, 1365, 1444, 1549, 1549],\n","        [ 106,   62,   51,   23,   23],\n","        [  87,   14,   25, 1636, 1636],\n","        [ 704,   12,  360,   12,   12],\n","        [   7,   62,   32, 1582, 1582],\n","        [1654,  448,  179, 1637, 1637],\n","        [1574,  443,   63,  297,  297],\n","        [1575,  437, 1445, 1638, 1638],\n","        [1576,   16,   16,   53,   53],\n","        [  95,   20,  115,    2,    2],\n","        [  12,   25,  498,    0,    0],\n","        [ 626, 1425,  225,    0,    0],\n","        [1644,  452,   87,    0,    0],\n","        [1655,   32,  506,    0,    0],\n","        [ 703,  724,  507,    0,    0],\n","        [ 267,  637,   45,    0,    0],\n","        [ 905, 1058,  445,    0,    0],\n","        [  59,   12,  446,    0,    0],\n","        [ 732,  447,   23,    0,    0],\n","        [ 224,  448,  447,    0,    0],\n","        [1656, 1426,  961,    0,    0],\n","        [  16, 1427,  453,    0,    0],\n","        [ 659,   12,   16,    0,    0],\n","        [ 571,  448,  115,    0,    0],\n","        [1490,  535,  498,    0,    0],\n","        [1657,   45,  225,    0,    0],\n","        [ 340,   12,   87,    0,    0],\n","        [ 201,  134, 1477,    0,    0],\n","        [   7,   16,   23,    0,    0],\n","        [1658,   12, 1447,    0,    0],\n","        [ 959,  134,  789,    0,    0],\n","        [ 703,  246, 1448,    0,    0],\n","        [1659, 1428, 1449,    0,    0],\n","        [ 205,   12,   16,    0,    0],\n","        [  37,  962,  135,    0,    0],\n","        [1220,  448,  179,    0,    0],\n","        [  23,  493, 1452,    0,    0],\n","        [ 889,   23,   71,    0,    0],\n","        [  16, 1429,  259,    0,    0],\n","        [  53,   12,   23,    0,    0],\n","        [   2,  631,  179,    0,    0],\n","        [   0,   16,  142,    0,    0],\n","        [   0,   93,  224,    0,    0],\n","        [   0, 1430,   12,    0,    0],\n","        [   0,   14, 1453,    0,    0],\n","        [   0,   12,   32,    0,    0],\n","        [   0, 1431,   12,    0,    0],\n","        [   0,   28,  703,    0,    0],\n","        [   0,   12,  988,    0,    0],\n","        [   0,  134,   16,    0,    0],\n","        [   0,  917, 1402,    0,    0],\n","        [   0,   12,   12,    0,    0],\n","        [   0,  448,  703,    0,    0],\n","        [   0,  493,   95,    0,    0],\n","        [   0,   16, 1450,    0,    0],\n","        [   0,   12,   45,    0,    0],\n","        [   0,  447, 1451,    0,    0],\n","        [   0,   42,  590,    0,    0],\n","        [   0,  138,   16,    0,    0],\n","        [   0, 1087,   93,    0,    0],\n","        [   0,   45, 1454,    0,    0],\n","        [   0,  191,  470,    0,    0],\n","        [   0,  452,   23,    0,    0],\n","        [   0,  348, 1455,    0,    0],\n","        [   0,   45, 1456,    0,    0],\n","        [   0,   12,  106,    0,    0],\n","        [   0,  600,  138,    0,    0],\n","        [   0,   16,   87,    0,    0],\n","        [   0, 1432,  565,    0,    0],\n","        [   0,   17,   55,    0,    0],\n","        [   0,   86,  704,    0,    0],\n","        [   0,  978, 1273,    0,    0],\n","        [   0,  179,  703,    0,    0],\n","        [   0,   81,   53,    0,    0],\n","        [   0,  589,    2,    0,    0],\n","        [   0, 1273,    0,    0,    0],\n","        [   0,  762,    0,    0,    0],\n","        [   0,   53,    0,    0,    0],\n","        [   0,    2,    0,    0,    0]])\n","mask: tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 1, 0, 0],\n","        [0, 1, 0, 0, 0],\n","        [0, 1, 0, 0, 0],\n","        [0, 1, 0, 0, 0],\n","        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n","max_target_len: 109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0yhWYwEMGbKn","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n","        super(EncoderRNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embedding = embedding\n","\n","        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n","        #   because our input size is a word embedding with number of features == hidden_size\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n","                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n","\n","    def forward(self, input_seq, input_lengths, hidden=None):\n","        # Convert word indexes to embeddings\n","        embedded = self.embedding(input_seq)\n","        # Pack padded batch of sequences for RNN module\n","        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        # Forward pass through GRU\n","        outputs, hidden = self.gru(packed, hidden)\n","        # Unpack padding\n","        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n","        # Sum bidirectional GRU outputs\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        # Return output and final hidden state\n","        return outputs, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6P8B9C_GbKp","colab_type":"code","colab":{}},"source":["# Luong attention layer\n","class Attn(torch.nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fVXPkg6GbKr","colab_type":"code","colab":{}},"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJgsDurPGbKu","colab_type":"code","colab":{}},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8Ify0p4GbKv","colab_type":"code","colab":{}},"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n","\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    lengths = lengths.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropatation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMvV-cJZGbKx","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n","\n","    # Load batches for each iteration\n","    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n","                      for _ in range(n_iteration)]\n","\n","    # Initializations\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Training loop\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Extract fields from batch\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Run a training iteration with batch\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Print progress\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            train_loss.append(print_loss_avg)\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","\n","        # Save checkpoint\n","        if (iteration % save_every == 0):\n","            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            torch.save({\n","                'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                'en_opt': encoder_optimizer.state_dict(),\n","                'de_opt': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3-WgqgtGbKz","colab_type":"code","outputId":"9256dcac-df21-4cf0-d6c7-63fb813e0721","executionInfo":{"status":"ok","timestamp":1588795429739,"user_tz":420,"elapsed":611,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Configure models\n","model_name = 'cb_model'\n","attn_model = 'dot'\n","#attn_model = 'general'\n","#attn_model = 'concat'\n","hidden_size = 512\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.1\n","batch_size = 64\n","train_loss=[]\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","loadFilename = None\n","#checkpoint_iter = 200000\n","#loadFilename = os.path.join(save_dir, model_name, corpus_name, \n","#                           '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size), \n","#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n","\n","# Load model if a loadFilename is provided\n","if loadFilename:\n","    # If loading on same machine the model was trained on\n","    checkpoint = torch.load(loadFilename)\n","    # If loading a model trained on GPU to CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","\n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Initialize encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z7DqJ0GrGbK1","colab_type":"text"},"source":["Run Training\n","~~~~~~~~~~~~\n","\n","Run the following block if you want to train the model.\n","\n","First we set training parameters, then we initialize our optimizers, and\n","finally we call the ``trainIters`` function to run our training\n","iterations.\n","\n","\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bu0HfsmmGbK2","colab_type":"code","outputId":"5ca6880b-47c7-4151-be5a-810da58477c0","executionInfo":{"status":"ok","timestamp":1588800418515,"user_tz":420,"elapsed":4936185,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["import time\n","\n","start_time = time.clock()\n","\n","# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.001 #original number was 0.0001\n","decoder_learning_ratio = 5.0\n","n_iteration = 400  #original number was 50000\n","print_every = 20\n","save_every = 50\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n","           print_every, save_every, clip, corpus_name, loadFilename)\n","\n","print(\"Done Training\")\n","print(\"Time elapsed in seconds : \", time.clock() - start_time)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Building optimizers ...\n","Starting Training!\n","Initializing ...\n","Training...\n","Iteration: 20; Percent complete: 5.0%; Average loss: 6.4871\n","Iteration: 40; Percent complete: 10.0%; Average loss: 5.8068\n","Iteration: 60; Percent complete: 15.0%; Average loss: 4.9009\n","Iteration: 80; Percent complete: 20.0%; Average loss: 3.8253\n","Iteration: 100; Percent complete: 25.0%; Average loss: 2.5091\n","Iteration: 120; Percent complete: 30.0%; Average loss: 1.4584\n","Iteration: 140; Percent complete: 35.0%; Average loss: 0.7174\n","Iteration: 160; Percent complete: 40.0%; Average loss: 0.2999\n","Iteration: 180; Percent complete: 45.0%; Average loss: 0.1238\n","Iteration: 200; Percent complete: 50.0%; Average loss: 0.0662\n","Iteration: 220; Percent complete: 55.0%; Average loss: 0.0271\n","Iteration: 240; Percent complete: 60.0%; Average loss: 0.0152\n","Iteration: 260; Percent complete: 65.0%; Average loss: 0.0105\n","Iteration: 280; Percent complete: 70.0%; Average loss: 0.0078\n","Iteration: 300; Percent complete: 75.0%; Average loss: 0.0064\n","Iteration: 320; Percent complete: 80.0%; Average loss: 0.0056\n","Iteration: 340; Percent complete: 85.0%; Average loss: 0.0047\n","Iteration: 360; Percent complete: 90.0%; Average loss: 0.0042\n","Iteration: 380; Percent complete: 95.0%; Average loss: 0.0039\n","Iteration: 400; Percent complete: 100.0%; Average loss: 0.0035\n","Done Training\n","Time elapsed in seconds :  4920.232576\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"esRt9U9zGbLI","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jW5388OdGbLJ","colab_type":"code","colab":{}},"source":["plt.plot(train_loss)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7Y-sY1JGbLL","colab_type":"text"},"source":["Run Evaluation\n","~~~~~~~~~~~~~~\n","\n","To chat with your model, run the following block.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"4PUsZxZ-GbLL","colab_type":"code","colab":{}},"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length):\n","        # Forward input through encoder model\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Initialize decoder input with SOS_token\n","        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n","        # Initialize tensors to append decoded words to\n","        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=device)\n","        # Iteratively decode one word token at a time\n","        if not USE_MULTINOMIAL:\n","            for _ in range(max_length):\n","                # Forward pass through decoder\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","                # Obtain most likely word token and its softmax score\n","                decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","                # Record token and score\n","                all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","                all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","                # Prepare current token to be next decoder input (add a dimension)\n","                decoder_input = torch.unsqueeze(decoder_input, 0)\n","            # Return collections of word tokens and scores\n","            return all_tokens, all_scores\n","        else:\n","            for _ in range(max_length):\n","                # Forward pass through decoder\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","                \n","                # Sample from the network as a multinomial distribution\n","                decoder_output_multi = decoder_output.data.view(-1).div(TEMP).exp()\n","                decoder_input = torch.multinomial(decoder_output_multi, 1)\n","                decoder_scores,_ = torch.max(decoder_output, dim=1)\n","                # Record token and score\n","                all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","                all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","                # Prepare current token to be next decoder input (add a dimension)\n","                decoder_input = torch.unsqueeze(decoder_input, 0)\n","            # Return collections of word tokens and scores\n","            return all_tokens, all_scores\n","            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tudhEfS5GbLN","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH, temperature = False):\n","    ### Format input sentence as a batch\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Create lengths tensor\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Transpose dimensions of batch to match models' expectations\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Use appropriate device\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(device)\n","    # Decode sentence with searcher\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","# def evaluateInput(encoder, decoder, searcher, voc, incoming_question):\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Get input sentence\n","            input_sentence = input('> ')\n","            # Check if it is quit case\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalize sentence\n","            input_sentence = normalizeString(input_sentence)\n","            # Evaluate sentence\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            EOS_first_occurence = output_words.index('EOS')\n","            if EOS_first_occurence > 1:\n","                output_words = output_words[0:EOS_first_occurence+1]\n","            # Format and print response sentence\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            final_output_words=\" \".join(output_words)\n","            print('Bot:', ' '.join(output_words))\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")\n","\n","    # try: \n","    #   input_sentence = incoming_question\n","    #   input_sentence = normalizeString(input_sentence)\n","    #   output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","    #   EOS_first_occurence = output_words.index('EOS')\n","    #   if EOS_first_occurence > 1:\n","    #       output_words = output_words[0:EOS_first_occurence+1]\n","    #   # Format and print response sentence\n","    #   output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","    #   final_output_words=\" \".join(output_words)\n","    #   return final_output_words\n","    # except Exception as err:\n","    #   print(\"________________________________________\")\n","    #   # print(err.message)\n","    #   # print(err.args)\n","    #   print(err)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"0K10X09dGbLO","colab_type":"code","outputId":"8ad5976f-f45d-48bb-ad69-cd1bcd91eeb7","executionInfo":{"status":"ok","timestamp":1588806619105,"user_tz":420,"elapsed":977685,"user":{"displayName":"Kavina Desai","photoUrl":"","userId":"16905396848653062769"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import pandas as pd\n","pd.set_option(\"display.max_colwidth\", 10000)\n","\n","chatbot_data = pd.read_csv(\"./some_chatbot_data.csv\", keep_default_na = False)\n","r, c = chatbot_data.shape\n","print(\"Number of rows : \", r)\n","print(\"Number of cols : \", c)\n","# print(\"Columns : \", list(chatbot_data.columns))\n","\n","print(\"Read csv data\")\n","# print(chatbot_data.head(5))\n","\n","column_names = [\"Original question\", \"Expected answer\", \"Actual answer\"]\n","result_df = pd.DataFrame(columns = column_names)\n","\n","USE_MULTINOMIAL = False\n","TEMP = 0.7\n","\n","# Set dropout layers to eval mode\n","encoder.eval()\n","decoder.eval()\n","\n","# Initialize search module\n","searcher = GreedySearchDecoder(encoder, decoder)\n","\n","# Begin chatting (uncomment and run the following line to begin)\n","evaluateInput(encoder, decoder, searcher, voc)\n","\n","# for i in range(0,r):\n","#     question = chatbot_data.loc[i][0]\n","#     answer = chatbot_data.loc[i][1]\n","#     links = chatbot_data.loc[i][2]\n","#     question = str(question).strip()\n","#     answer = str(answer).strip()\n","#     links = str(links).strip()\n","#     if \"\\n\" in question:\n","#         question = question.replace(\"\\n\", \" \")\n","#         question = re.sub(r'\\s+', ' ', question)\n","#     if \"\\n\" in answer:\n","#         answer = answer.replace(\"\\n\", \" \")\n","#         answer = re.sub(r'\\s+', ' ', answer)\n","#     if \"\\n\" in links:\n","#         links = links.replace(\"\\n\", \" \")\n","#         links = re.sub(r'\\s+', ' ', links)\n","\n","#     expected_answer = answer + links\n","#     actual_answer = evaluateInput(encoder, decoder, searcher, voc, question)\n","\n","#     result_df = result_df.append(pd.Series([question, expected_answer, actual_answer], index=result_df.columns ), ignore_index=True)\n","\n","# result_df.to_csv('resultant_data13.csv', index=False)\n","# print(\"DONE !!!!!\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Number of rows :  150\n","Number of cols :  3\n","Read csv data\n","> Why should I connect my LinkedIn profile to my San Jose State LinkedIn Learning account?\n","Bot: you will need to have a richer and more personalized learning experience powered by the data and insights of the linkedin network based on what other professionals like you are watching . \"\n","> q\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvNNCVf7GbLQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}